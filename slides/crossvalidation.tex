\renewcommand{\arraystretch}{1}

\newcommand{\h}[1]{\textup{\lstinline{#1}}}
\lstnewenvironment{code}
    %{\lstset{}%
      %\csname lst@SetFirstLabel\endcsname}
    %{\csname lst@SaveFirstLabel\endcsname}
    {
    \lstset{
      basicstyle=\small\ttfamily,
      xleftmargin=\parindent,
      xleftmargin=\parindent,
      flexiblecolumns=false,
      keepspaces=true,
      frame=single,
      basewidth={0.5em,0.45em},
      literate={+}{{$+$}}1 {/}{{$/$}}1 {*}{{$*$}}1 {=}{{$=$}}1
               {>}{{$>$}}1 {<}{{$<$}}1 {\\}{{$\lambda$}}1
               {\\\\}{{\char`\\\char`\\}}1
               {->}{{$\rightarrow$}}2 {>=}{{$\geq$}}2 {<-}{{$\leftarrow$}}2
               {<=}{{$\leq$}}2 {=>}{{$\Rightarrow$}}2 
%                {\ .}{{$\circ$}}2 {\ .\ }{{$\circ$}}2
               {>>}{{>>}}2 {>>=}{{>>=}}2
               {|}{{$\mid$}}1               
               {<>}{{$\diamond$}}1          
               {++}{{$\+$}}1                
               {mempty}{{$\epsilon$}}1               
               {Theta}{{$\Theta$}}1               
    }
    }
    {}

\newcommand{\set}[1]{\ensuremath{\mathcal{{#1}}}}
%\newcommand{\vector}[1]{\textbf{{{#1}}}}
\newcommand{\elem}[1]{\textbf{{#1}}}
\newcommand\op{\ensuremath{\diamond}}
\newcommand\id{\ensuremath{\mathbf{epsilon}}}
\newcommand\+{\op}
%\newcommand\+{\mdoubleplus}
\newcommand\doubleplus{+\kern-1.3ex+\kern0.8ex}
\newcommand\mdoubleplus{\ensuremath{\mathbin{+\mkern-10mu+}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Merging gives us: fast cross-validation}

traditional pseudocode:
\begin{code}
for i = 1..n
    let test_datapoint = i_th datapoint in dataset
    let train_dataset  = dataset - test_datapoint

    train on train_dataset  
    infer on test_datapoint
    calculate loss        

return mean and stddev of losses
\end{code}

%running time: $\Theta\left(k (t(n-\frac{n}{k}) +  i(\frac{n}{k}) + \frac{n}{k})\right)$
%\vspace{0.15in}
%running time: $\Theta(nt(n-1) + ni(1))$
%\vspace{0.15in}

\vspace{0.1in}
traditional run times:
\vspace{0.1in}

\centering
\begin{tabular}{l|cc|cc}
%\hline
& training & inference & LOO cv & $k$-fold cv \\ %leave-one-out \\ 
%algorithm & t(n) & i(1) & overall \\ %leave-one-out \\ 
\hline
ridge regression & $O(n)$ & $O(1)$ & $O(n^2)$ & $O(kn)$ \\
%\hline
%naive bayes (normal dist) & $O(n)$ & $O(1)$ & $O(n^2)$ \\
%$k$-nn (cover tree) & $O(n\log n)$ & $O(\log n)$ & $O(n^2\log n)$ \\
%\hline
\end{tabular}

\end{frame}

\begin{frame}[fragile]{Merging gives us: fast cross-validation}

\begin{tikzpicture}

\node at (0.775in,2) {
    \includegraphics[width=1.6in]{/home/user/docs/research/presentation_lib/dna/long}
};

\foreach \i in {0,1,...,10} {
    %\node[draw,minimum size=0.15in] at (\i*0.15in,1.5) {};
    \uncover<2->{
    \node[fill=black,minimum size=0.15in,draw=white,line width=1pt] at (\i*0.15in,1) {};
    }
}

\uncover<3->{
\foreach \i in {1,...,9} {
    %\foreach \j in {0,...,\i} {
        %\node[fill=black,minimum size=0.15in,draw=white,line width=1pt] at (\j*0.15in,-\i*0.375-0.375) {};
        \node[fill=black,minimum height=0.15in,minimum width=\i*0.15in,draw=white,line width=1pt] at (\i*0.075in-0.075in,-\i*0.375) {};
    %}
}
}

\uncover<4->{
\foreach \i in {0,...,9} {
    %\foreach \j in {\i,...,9} {
        %\node[fill=black,minimum size=0.15in,draw=white,line width=1pt] at (\j*0.15in+0.15in,-\i*0.375) {};
        \node[fill=black,minimum height=0.15in,minimum width=1.5in-\i*0.15in,draw=white,line width=1pt] at (\i*0.075in+0.825in,-\i*0.375) {};
    %}
}
}

\uncover<2>{\node[minimum width=2.8in,minimum height=0.35in,fill=green,opacity=0.2] at (3.2in,0.85in) {};}
\uncover<3>{\node[minimum width=2.8in,minimum height=0.5in,fill=green,opacity=0.2] at (3.2in,0.25in) {};}
\uncover<4>{\node[minimum width=2.8in,minimum height=0.5in,fill=green,opacity=0.2] at (3.2in,-0.4in) {};}
\uncover<5>{\node[minimum width=2.8in,minimum height=0.65in,fill=green,opacity=0.2] at (3.2in,-1.15in) {};}

\node[text width=2.8in] at (3.2in,-1) {
\begin{code}
for i = 1..n
    m[i] <- train on dp[i]

prefix[1] = empty
for i = 2..n
    prefix[i]=merge(prefix[i-1],m[i-1])

suffix[n] = empty 
for i = n-1..1
    suffix[i]=merge(suffix[i+1],m[i+1])

for i = 1..n
    m <- merge(prefix[i], suffix[i])
    infer on dp i with m   
    calculate loss

return mean and stddev of losses
\end{code}

%\begin{tikzpicture}
%\node[draw] {
%\lstinline{calculate prefixes   -- time n*t(n)}
%\lstinline{calculate suffixes   -- time n*t(n)}
%%\lstinline{}
%\lstinline{for i = 1..n}
%\lstinline{    merge rows           -- time n*beta(n)}
%\lstinline{    inference            -- time n*i(1)}

%};
%\end{tikzpicture}
};

\end{tikzpicture}

%\vspace{0.15in}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\arraystretch}{1.5}
\begin{frame}{Fast cross-validation summary}
%\footnotesize
\begin{center}
%\begin{tabular}{l|ccc|cc}
%\hline
%algorithm & training & inference & monoid & standard cv & fast cv \\
%%algorithm & $t(n)$ & $i(n)$ & $\beta(n)$ & standard & monoid \\
%\hline
%\hline
%normal distribution & $\Theta(n)$ & $\Theta(1)$ & $\Theta(1)$ & $\Theta(n^2)$ & $\Theta(n)$ \\
%kernel density & $\Theta(n\log n)$ & $\Theta(\log n)$ & $\Theta(n)$ & $\Theta(n^2\log n)$ & $\Theta(n^2)$ \\
%\hline
%\end{tabular}

    Assuming merging takes constant time (as in ridge regression), then:
    \vspace{0.30in}

%\begin{tikzpicture}[node distance=2.5cm, auto, >=stealth]
%
%\node at (1.4in,1.5in) {
\begin{tabular}{l|cc}
%\hline
& LOO cv & $k$-fold cv \\
%algorithm & $t(n)$ & $i(n)$ & $\beta(n)$ & standard & monoid \\
%\hline
\hline
standard & $O(n^2)$ & $O(kn)$ \\
fast & $O(n)$ & $O(n)$ \\
%\hline
%\uncover<3->{abelian group cv & $O(n)$ & $O(n\log n)$ } \\
%\uncover<4->{double monoid cv & --- & $O(n\log n)$ } \\
%\hline
\end{tabular}

\vspace{0.3in}
Also works when merging takes non-constant time

(but more complicated runtime expressions)
%};
%\uncover<1>{ \node[fill=white,minimum width=4.5in,minimum height=2in] at (1.4in,0.5in) {}; }
%\uncover<2,3>{ \node[fill=white,minimum width=4.5in,minimum height=1in] at (1.4in,0.5in) {}; }

%\begin{tabular}{l|cccc}
%\hline
%algorithm & standard cv & monoid cv  & abelian group cv & double monoid cv\\
%%algorithm & $t(n)$ & $i(n)$ & $\beta(n)$ & standard & monoid \\
%\hline
%\hline
%normal distribution & $O(n^2)$ & $O(n)$ & $O(n)$ & $O(n)$ \\
%kernel density & $O(n^2\log n)$ & $O(n^2)$ & $O(n\log n)$ & $O(n\log n)$ \\
%\hline
%\end{tabular}

%\uncover<1->{
%\node[blackbox] (dataset) [minimum height=0.3in] {data set};
%\node[blackbox] (model)   [minimum height=0.3in, node distance=1.5in,right of = dataset] {model};
%\node[blackbox] (answer)  [minimum height=0.3in, node distance=1.5in,right of = model] {result};
%\draw[->,line width=2pt] (dataset) to node[above] {\h{train}} (model);
%\draw[->,line width=2pt] (model) to node[above] {\h{inference}} (answer);
%}
%
%\uncover<2>{
%\node (l1) [color=blue] at (-0.1,-1.3) {free monoid};
%\node (l2) [color=blue] at (2,1.3) {homomorphism};
%\node (l3) [color=blue] at (4,-1.3) {monoid};
%
%\draw[->,color=blue,ultra thick] (l1) to (dataset);
%\draw[->,color=blue,ultra thick] (l2) to (2,0.5);
%\draw[->,color=blue,ultra thick] (l3) to (model);
%}
%
%
%\uncover<3>{
%\node (l1) [color=blue] at (-0.1,-1.3) {free abelian group};
%\node (l2) [color=blue] at (2,1.3) {homomorphism};
%\node (l3) [color=blue] at (4,-1.3) {abelian group};
%
%\draw[->,color=blue,ultra thick] (l1) to (dataset);
%\draw[->,color=blue,ultra thick] (l2) to (2,0.5);
%\draw[->,color=blue,ultra thick] (l3) to (model);
%}
%
%\uncover<4>{
%\node (l1) [color=blue] at (-0.1,-1.3) {free monoid};
%\node (l2) [color=blue] at (1.9,1.3) {homomorphism};
%\node (l3) [color=blue] at (4,-1.3) {monoid};
%\node (l4) [color=blue] at (5.8,1.3) {homomorphism};
%\node (l5) [color=blue] at (8,-1.3) {monoid};
%
%\draw[->,color=blue,ultra thick] (l1) to (dataset);
%\draw[->,color=blue,ultra thick] (l2) to (2.1,0.5);
%\draw[->,color=blue,ultra thick] (l3) to (model);
%\draw[->,color=blue,ultra thick] (l4) to (5.6,0.5);
%\draw[->,color=blue,ultra thick] (l5) to (answer);
%}
%
%\end{tikzpicture}
\end{center}
\end{frame}
\renewcommand{\arraystretch}{1}

