\documentclass[../main.tex]{subfiles}
 
\newcommand{\set}[1]{\mathcal {#1}}
\newcommand{\sized}[1]{\tilde \set {#1}}

\newcommand{\radius}{r}
\newcommand{\dist}[2]{\distf({#1},{#2})}
\newcommand{\distf}{d}
\newcommand{\diam}[1]{\text{diam}({#1})}
\newcommand{\codiam}[1]{\text{codiam}({#1})}
\newcommand{\aspect}[1]{\Delta({#1})}

\newcommand{\minkdim}{\text{dim}_\text{Mink}}
\newcommand{\krdim}{\text{dim}_\text{kr}}
\newcommand{\doubdim}{\text{dim}_\text{doub}}

\newcommand{\krnum}{c_\text{kr}}
\newcommand{\doubnum}{c_\text{doub}}

\newcommand{\p}{\ensuremath p}
\newcommand{\q}{\ensuremath q}
%\newcommand{\level}[1]{\text{\ttfamily level}}
%\newcommand{\children}[1]{\text{\ttfamily children}}
%\newcommand{\covdist}[1]{\ensuremath{\textup{\text{\ttfamily covdist}}
\newcommand{\level}[1]{\ensuremath{\textup{\text{\ttfamily level}({#1})}}}
\newcommand{\parent}[1]{\ensuremath{\textup{\text{\ttfamily parent}({#1})}}}
\newcommand{\children}[1]{\ensuremath{\textup{\text{\ttfamily children}({#1})}}}
\newcommand{\covdist}[1]{\ensuremath{\textup{\text{\ttfamily covdist}({#1})}}}
\newcommand{\descendants}[1]{\ensuremath{\textup{\text{\ttfamily descendants}({#1})}}}
\newcommand{\maxdist}[1]{\ensuremath{\textup{\text{\ttfamily maxdist}({#1})}}}

% FIXME: should these be changed?
\newcommand{\nn}[1]{\ensuremath{\ensuremath{{{#1}}_{nn}}}}
\newcommand{\exprad}[1]{\ensuremath{\ensuremath{2}}}
\newcommand{\pack}{\ensuremath{\text{\ttfamily pack}}}
\newcommand{\rmNodes}{\ensuremath{\text{\ttfamily rmNodes}}}
\newcommand{\findnn}{\ensuremath{\text{\ttfamily findNearestNeighbor}}}
\newcommand{\ctmerge}{\ensuremath{\text{\ttfamily merge}}}
\newcommand{\ctinsert}{\ensuremath{\text{\ttfamily insert}}}
\newcommand{\ctinsertHelper}{\ensuremath{\text{\ttfamily insert\_}}}
\newcommand{\rebalance}{\ensuremath{\text{\ttfamily rebalance}}}
\newcommand{\rebalanceHelper}{\ensuremath{\text{\ttfamily rebalance\_}}}
\newcommand{\mkfunction}[1]{\ensuremath{\text{\ttfamily {#1}}}}
\newcommand{\mkvar}[1]{\ensuremath{\text{\emph{{#1}}}}}
\newcommand{\nullvar}{\ensuremath{\textup{\text{\ttfamily null}}}}
\newcommand{\datapoint}[1]{\ensuremath{\textup{\text{\ttfamily dp}({#1})}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\chapter{Cover Trees}

\begin{definition}
    A set $\set X$ equipped with a distance function $\distf : \set X \times \set X \to \R$ is a \emph{metric space} if it obeys the following properties:
    \begin{enumerate}
        %\item \emph{Non-negativity}.  For all $x_1,x_2\in\set X$, $\dist{x_1}{x_2} \ge 0$.
        \item \emph{Indiscernability}.  For all $x_1,x_2\in\set X$, $\dist{x_1}{x_2} = 0$ if and only if $x_1=x_2$.
        \item \emph{Symmetry}. For all $x_1,x_2\in\set X$, $\dist{x_1}{x_2} = \dist{x_2}{x_2}$.
        \item \emph{Triangle inequality}.  For all $x_1,x_2,x_3\in\set X$, $\dist{x_1}{x_2} + \dist{x_2}{x_3}\ge\dist{x_1}{x_3}$.
    \end{enumerate}
\end{definition}

\subsection{Examples of Metric Spaces}

\begin{example}
    Any subset of a metric space is also a metric space.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The tree definition}

\begin{definition}
    A \emph{simplified cover tree} is any tree obeying the following three invariants.
    \begin{enumerate}
        \item \emph{The leveling invariant}.
        Every node $\p$ has an associated integer $\level\p$.
        For all nodes $\q\in\children\p$, $\level\q < \level\p$.
        \item \emph{The covering invariant}.
        Every node $\p$ has an associated real number $\covdist\p=2^{\level\p}$.
        For all nodes $\q\in\children\p$, $\dist \p \q \le \covdist\p$.
        \item \emph{The separating invariant}.
        For all nodes $\q_1,\q_2\in\children\p$, $\dist {\q_1} {\q_2} \le \covdist\p/4$.
    \end{enumerate}
\end{definition}

\begin{remark}
    The original version of the simplified cover tree had a slightly different leveling invariant.
    The version used in this paper is strictly more general;
    it facilitates the removal of nodes from the cover tree,
    but makes the procedure for insertion slightly more complicated.
\end{remark}

Throughout this paper, we will use the functions $\children\p$ and $\descendants\p$ to refer to the set of nodes that are children or descendants of $p$ respectively.
We also define the function \mkfunction{maxdist} as
$$
\maxdist p = \argmax_{q\in\descendants{p}} \dist p q
$$
In words, this is the greatest distance from $p$ to any of its descendants.
This value is upper bounded by $2^{\level{p}+1}$, and its exact value can be cached within the data structure.\footnote{
    As in the original cover tree, practical performance is improved on most datasets by redefining $\covdist p = 1.3 ^ {\level p}$.
    All of our experiments use this modified definition.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{algorithm}[H]
    \caption{Simplified cover tree nearest neighbor query}
    \label{alg:query}

    \vspace{0.1in}
{\bfseries function} \findnn(cover tree $p$, query  point $x$, nearest neighbor so far $y$)

\begin{algorithmic}[1]
    \If {$d(p,x) < d(y,x)$}
        \State $y \leftarrow p$
    \EndIf
    \For {each child $q$ of $p$ sorted by distance to $x$}
        \If {$d(y,x) > d(y,q) - \maxdist{q}$} %2^{\level q}$}
            \State $y \leftarrow \findnn(q,x,y)$
        \EndIf
    \EndFor
    \State\Return $y$
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{algorithm}[H]
\caption{Simplified cover tree insertion}
\label{alg:insert}

    \vspace{0.1in}
{\bfseries function} \ctinsert(cover tree $p$, data point $x$)

\begin{algorithmic}[1]
    \If {$\dist p x > \covdist p$}
        \While {$\dist p x > 2\covdist p$}
            \State Remove any leaf $q$ from $p$
            \State $p' \leftarrow $ tree with root $q$ and $p$ as only child
		  \State $p \leftarrow p'$
        \EndWhile
        \State\Return tree with $x$ as root and $p$ as only child
    \EndIf
    \State\Return \ctinsertHelper($p$,$x$)
\end{algorithmic}

{\bfseries function} \ctinsertHelper(cover tree $p$, data point $x$)

\emph{prerequisites:} $\dist p x \le \covdist p$

\begin{algorithmic}[1]
    \For {$q \in \children{p}$}
        \If {$\dist q x \le \covdist q$}
            \State $q' \leftarrow \ctinsertHelper(q,x)$
            \State $p' \leftarrow p$ with child $q$ replaced with $q'$
            \State \Return $p'$
        \EndIf
    \EndFor
    \State\Return $p$ with $x$ added as a child
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{What is the dimension of a metric space?}

In this section we introduce two 

\begin{definition}
%A ball of radius $\radius$ in a metric space $\set X$ is defined to be
    We let $B_\set X(x,\radius)$ denote the ball centered around $x$ of radius $r$ in metric space $\set X$.
    That is,
\begin{equation}
B_\set X(x,\radius) = \{ y : y\in\set X, \dist{x}{y} \le \radius \}.
\end{equation}
\end{definition}

\begin{definition}
    Let $\set X$ be a metric space, and let $\mu : \{\set X\} \to \R^+$ be a measure on $\set X$.
    Then the \emph{expansion constant} is defined as
    \begin{equation}
        c_\set X = \max_{x\in\set X, \radius\in\R^+} \frac{\mu B_{\set X}(x,2\radius)}{\mu B_{\set X}(x,\radius)}
        ,
    \end{equation}
    and the \emph{expansion dimension} is defined as
    \begin{equation}
        \krdim\set X = \log_2 c_\set X
        .
    \end{equation}
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{definition}
    A $\delta$-covering of a metric space $\set X$ is a set $\{x_1,x_2,...,x_n\} \subseteq \set X$ such that for all $x\in\set X$, there exists an $x_i$ such that $\dist{x}{x_i} < \delta$.
    The $\delta$-covering number $N_\delta(\set X)$ is the cardinality of the smallest $\delta$-covering.
    The log of the covering number $\log N_\delta(\set X)$ is called the metric entropy of $\set X$.
\end{definition}

\begin{definition}
A $\delta$-packing of a metric space $\set X$ is a set $\{x_1,x_2,...,x_M\} \subseteq \set X$ such that $\dist{x_i}{x_j} > \delta$ for all distinct $i,j\in[M]$.
The $\delta$-packing number $M_\delta (\set X)$ is the cardinality of the largest $\delta$-packing.
\end{definition}

\begin{lemma}
    \label{lemma:coverpacking}
    For any metric space $\set X$ and any $\delta>0$,
    \begin{equation}
        M_{2\delta}(\set X) \le N_\delta(\set X) \le M_{\delta}(\set X)
        .
    \end{equation}
\end{lemma}

\begin{proof}
    To prove the first inequality, let $P$ be a $2\delta$-packing and $C$ be a $\delta$-cover of $\set X$.
    For every point $p\in P$, there must exist a $c\in C$ such that $\dist{p}{c}\le\delta$.
    No other $p'\in P$ can also satisfy $\dist{p'}{c}\le\delta$, because then by the triangle inequality
    \begin{equation}
        \dist{p'}{p} \le \dist{p'}{c}+\dist{p}{c} \le 2\delta
        ,
    \end{equation}
    which would contradict that $P$ is a $2\delta$-packing.
    In other words, for each $c\in C$, there is at most one $p\in P$.
    So $N_\delta \ge |C| \ge |P| \ge M_{2\delta}$.

    To prove the second inequality, let $\set X'\subseteq \set X$ be a maximal $\delta$-packing.
    Then there does not exist an $x\in\set X$ such that for all $x'\in\set X'$, 
    $\dist{x}{x'} > \delta$.
    (Otherwise, $\set X' \cup \{x\}$ would be a packing larger than $\set X'$.)
    Hence, $\set X'$ is also a $\delta$-cover,
    and the smallest $\delta$-cover can be no larger.
\end{proof}

%\cite{nickl2007bracketing} uses metric entropy to prove a version of the central limit theorem.
%
%\begin{example}
%\end{example}

%\begin{definition}
    %The Minkowski dimension of a metric space is defined to be
    %\begin{equation}
        %\minkdim \set X = \lim_{\delta\to0} \frac{\log N_\delta(\set X)}{\log 1/\delta}
        %.
    %\end{equation}
%\end{definition}
%
%\begin{example}
    %Let $\set X$ be a finite metric space.
    %Then $\minkdim \set X = 0$.
%\end{example}

\begin{definition}
    The \emph{doubling number} of a metric space is
    \begin{equation}
        \doubnum(\set X) = \max_{x\in\set X, \radius\in\R^+} N_\radius(B_{\set X}(x,2\radius))
        .
    \end{equation}
    The \emph{doubling dimension} of a metric space $\set X$ is the log of the doubling number.
    Specifically,
    \begin{equation}
        \doubdim \set X = \log \doubnum\set X = \max_{x\in\set X, \radius\in\R^+} \log N_\radius(B_{\set X}(x,2\radius))
        .
    \end{equation}
\end{definition}
\cite{gupta2003bounded}

\begin{lemma}[\cite{krauthgamer2004navigating},\cite{gupta2003bounded}]
    Every finite metric $(\set X,d)$ satisfies
    \begin{equation}
        \doubdim\set X \le 4\cdot\krdim\set X
        .
    \end{equation}
\end{lemma}
%\begin{proof}
    %Let $k=\krdim(\set X)$.
    %Fix some ball $B(x,2r)$.
    %We will show that $B(x,2r)$ can be covered by $k^4$ balls of radius $r$.
%\end{proof}

\begin{definition}
    Let $\set X$ be a finite metric space.
    The \emph{diameter} of $\set X$, denoted by $\diam{\set X}$, is the maximum distance between any two points.
    The \emph{separation} of $\set X$, denoted by $\codiam{\set X}$, is the minimum distance between any two points.
    The \emph{aspect ratio} of $\set X$, denoted by $\aspect{\set X}$, is the ratio of the diameter to the dispersion.
\end{definition}

\cite{bartal2003metric} discusses the relation between aspect ratios and tree metrics.

\begin{example}
    This example shows that there is not necessarily a relationship between the aspect ratio of a metric and either its expansion or doubling constants.
    Let $\set Y=\{y_1,...,y_n\}$ be the discrete metric space of size $n$;
    that is,
    \begin{equation}
        \dist{y_i}{y_j}=
        \begin{cases}
            0 & i = j \\
            1 & \text{otherwise}
        \end{cases}
        .
    \end{equation}
    Then the aspect ratio of $\set Y$ is 1 (i.e. as small as possible),
    and both the expansion and doubling constants of $\set Y$ are $n-1$ (i.e. arbitrarily large).
    Now construct the set $\set Y'=\{y'_1, y'_2, y'_3\}$.
    Let $r>2$, and define the distance function to be
    \begin{equation}
        d(y'_i,y'_j) =
        \begin{cases}
            0 & i=j \\
            1 & i=1, j=2 \\
            r & i=1, j=3 \\
            r & i=2, j=3 \\
        \end{cases}
        .
    \end{equation}
    Then the aspect ratio is $r$ (i.e. arbitrarily large),
    but the expansion constant is always 2
    and the doubling constant always 1.
\end{example}

\begin{definition}
    Let $\set X$ be a metric space with a probability measure $\mu$, and
    let $x$ be a random variable sampled according to $\mu$.
    We say that $\mu$ is \emph{$\sigma$-subgaussian} if there exists an $\bar x\in\set X$ such that
    \begin{equation}
        \prob{\dist{x}{\bar x}\le t} \ge 1-\exp(-\sigma^2t^2)
        .
    \end{equation}
    We further say that $\mu$ is \emph{bounded} if 
    the density of $\dist{x}{\bar x}$ is bounded.
\end{definition}

%\begin{example}
    %The definition above of a subgaussian distribution is a generalization of the definition for vector spaces.
%\end{example}
%
%\begin{lemma}
    %Let $\set X$ be a metric space with subgaussian probability measure $\mu$.
    %Let $x_1,x_2$ be i.i.d.\ random variables distributed according to $\mu$.
    %Then,
    %\begin{equation}
    %\end{equation}
%\end{lemma}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{lemma}
    Let $\set X$ be a metric space.
    Let $X=\{x_1,...,x_n\}\subset\set X$ be a sample of $n$ i.i.d.\ points satisfying the following property:
    There exists a $\bar x\in\set X$ such that $\mu=\E\dist{\bar x}{x_i}$ is finite.
    Then, 
    \begin{equation}
        \E\diam{X} \le 2n\mu
    \end{equation}
\end{lemma}

\begin{proof}
    By the triangle inequality, we have that
    \begin{align}
        \diam{X}
        &= 
        \max_{i,j} \dist{x_i}{x_j}
        \le
        \max_{i,j} (\dist{\bar x}{x_i} + \dist{\bar x}{x_j})
        %\\ &=
        %\max_i \dist{\bar x}{x_i} + \max_j\dist{\bar x}{x_j}
        =
        2\max_i \dist{\bar x}{x_i}
        .
    \end{align}
    And so,
    \begin{align}
        \prob{\diam{X} > t}
        & \le
        \prob{\max_i 2\dist{\bar x}{x_i} > t}
        \\ &\le
        \sum_{i=1}^n\prob{2\dist{\bar x}{x_i} > t}
        \label{eq:Ediamub}
        \\ &=
        n\prob{2\dist{\bar x}{x_1} > t}
        \label{eq:Ediamiid}
        .
    \end{align}
    Equation \eqref{eq:Ediamub} follows from the union bound, 
    and \eqref{eq:Ediamiid} follows because the $x_i$s are i.i.d.
    Since the diameter is always nonnegative, 
    \begin{align}
        \E\diam{X} 
        &= 
        \int_0^\infty \prob{\diam{X} > t} dt
        \\ &\le
        \int_0^\infty n\prob{2\dist{\bar x}{x_1} > t} dt
        \\ &=
        n\int_0^\infty \prob{2\dist{\bar x}{x_1} > t} dt
        \\ &=
        2n \E\dist{\bar x}{x_1}
        \label{eq:Ediamproof}
        .
    \end{align}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{lemma}
    Let $\set X$ be a metric space.
    Let $\mu$ be a distribution over $\set X$ with bounded density and finite expectation.
    Let $X=\{x_1,...,x_n\}\subset\set X$ be a sample of $n$ i.i.d.\ points from $\mu$.
    Then the expected aspect ratio of $X$ is polynomial in $n$.
    Specifically, 
    \begin{equation}
        \E\aspect{X}\le2n^3B\E\dist{\bar x}{x_1}. 
    \end{equation}
\end{lemma}

\begin{proof}
    The proof proceeds by first upper bounding the diameter of $X$,
    then lower bounding the codiameter.
    %Then,
    %\begin{align}
        %\prob{\diam{X} \le 2t}
        %& \ge
        %\prob{\max_i \dist{\bar x}{x_i} \le t}
        %\\ & =
        %\prob{\dist{\bar x}{x_1} \le t}^n
        %\\ & \ge
        %(1-\exp(-\sigma^2t^2))^n
        %\\ & \ge
        %1-n\exp(-\sigma^2t^2)
        %.
    %\end{align}
    %Substituting $t=\sqrt{s\log n/\sigma^2}$ gives
    %\begin{align}
        %\prob{\diam{X} \le 2\sqrt{\frac{s\log n}{\sigma^2}}} 
        %& \ge 
        %1 - n\exp(-s \log n)
        %\\ &=
        %1 - n^{-s}
        %\\ &\ge
        %1 - \exp(-s)
        %.
    %\end{align}
    %The last inequality holds whenever $s\ge1$ and $n\ge\exp(1)$,
    %as required by the lemma's conditions.
    Next we lower bound the codiameter of $X$.
    We have that
    \begin{align}
        \prob{\codiam{X} \le t}
        &=
        \prob{\min \{ \dist{x_i}{x_j} : i\in\{1,...,n\}, j\in\{i+1,...,n\} \} \le t}
        %\prob{\min_{i\ne j} \dist{x_i}{x_j} \le t}
        \\ &\le 
        \sum_{i=1}^n\sum_{j=i+1}^n \prob{\dist{x_i}{x_j} \le t}
        \\ &\le
        \sum_{i=1}^n n \max_{x\in X} \prob{\dist{x_i}{x} \le t}
        \\ & =
        n^2 \max_{x\in X} \prob{\dist{x_1}{x} \le t}
        \\ & \le 
        n^2 B t
    \end{align}
    Further, since probabilities are always no greater than 1,
    \begin{equation}
        \prob{\codiam{X}\le t} \le \max\{1,n^2Bt\}
        .
    \end{equation}
    Since $\codiam{X}$ is nonnegative, we have that 
    \begin{align}
        \E \codiam{X}
        &=
        \int_0^\infty (1-\prob{\codiam{X} \le t}) dt
        %\\ & =
        %\int_0^\infty \prob{\codiam{X} > t} dt
        \\ & \ge
        \int_0^\infty (1-\max\{1,n^2 Bt\})dt
        \\ & = 
        \int_0^{(n^2B)^{-1}} (1 - n^2 Bt) dt
        \\ & =
        %\frac{1}{n^2B} - \frac{\left(\frac{1}{n^2B}\right)^3}{2}
        %\\ & \ge
        \frac{1}{2n^2B}
        \label{eq:Ecodiamproof}
        .
    \end{align}
    Combining Equations \eqref{eq:Ediamproof} and \eqref{eq:Ecodiamproof} gives that $\E\aspect{X} \le 2n^3B\E\dist{\bar x}{x_1}.$
\end{proof}

\begin{lemma}[\cite{krauthgamer2004navigating}]
    For any metric space $\set X$, we have that
    %\begin{equation}
    $
        |\set X| \le \aspect{\set X}^{O(\doubdim{\set X})}.
    $
    %\end{equation}
\end{lemma}
\begin{proof}
    %Assume wlog that the separation distance is 1
    %(we can rescale all the distances to ensure this).
    %Then the diameter of $\set X$ is $\aspect{\set X}$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Analysis}

\begin{table}[H]
    \small
    %\newcolumntype{Y}{>{\centering\arraybackslash}p{1in}}
    %\newcolumntype{Y}{p{0.1in}}
    %\begin{tabularx}{\textwidth}{lXXY}
    \centering
    \begin{tabular}{lccc}
        \toprule
        \vspace{-0.25in}
        &~\hspace{1.2in}~&~\hspace{1.2in}~&~\hspace{1.2in}~\\
        data structure & space & find nearest neighbor & insertion \\
        \midrule
        ball tree \cite{} & $O(n)$ & $O(n)$ & $O(n)$ \\
        metric skip list \cite{karger2002finding} & $O(n\log n)$ & $\krnum{}^{O(1)}\log n$ & $\krnum^{O(1)}\log n\log\log n$ \\
        navigating net \cite{} & $O(n)$ \\
        cover tree \cite{} & $O(n)$ & $O(\krnum^8\log n)$ & $O(\krnum^{12}\log n)$ \\
        simplified cover tree & $n$ & $O(\doubnum{}\aspect{}\log n)$ \\
        \bottomrule
    \end{tabular}
    %\end{tabularx}
    \caption{
        Summary of the runtime and space usage of several nearest neighbor data structures.
        Here $n$ represents the size of the dataset.
    }
\end{table}

\begin{lemma}
    %The number of children for any node in the tree is bounded by the doubling number of the space.
    For every node $p$ in a cover tree, we have that
    \begin{equation}
        |\children\p| \le \doubnum \set X
        .
    \end{equation}
\end{lemma}

\begin{proof}
    Let $\delta=\covdist p/2$.
    Recall that the separating invariant ensures that for all nodes $q_1,q_2\in\children p$,
    $\dist{q_1}{q_2}\le2\delta$.
    So the set \children p is a $2\delta$-packing of $B(p,2\delta)$.
    By Lemma \ref{lemma:coverpacking}, this packing can be no larger than the smallest $\delta$-covering,
    which by definition can be no larger than $\doubnum \set X$.
\end{proof}

\begin{lemma}
    The depth of a cover tree is upper bounded by the log of the data set's aspect ratio.
\end{lemma}

\begin{proof}
    We will bound the level of the root and bottommost lead nodes.

    Let $p$ be the root of the tree.
    By the covering invariant, we have that the maximum distance from $p$ to a child is $\covdist{p}=2^\level p$; 
    the maximum distance to a grandchild is $2^\level p + 2^{level p-1}$;
    and the maximum distance to a descendent in the $n$th generation is $\sum_{i=0}^{n-1} 2^{\level p-i}$.
    This distance is upper bounded by $2^{\level p+1}$.
    So we have that $\level{p}\le\diam{\set X}$.
    %\begin{equation}
    %$    2\cdot2^\level{p} = 2\cdot\covdist{p}\le\diam{\set X}$, so $\level{p}\le\log_2\diam{\set X}$.
    %\end{equation}

    Let $q$ be the bottommost leaf in the tree.
    We have that $2^\level{\parent{q}} = $
\end{proof}

\end{document}
